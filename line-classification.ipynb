{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_entity_text(regions):\n",
    "    result = ''\n",
    "    for region in regions:\n",
    "        if region['type'] == 'PARAGRAPH':\n",
    "            for line in region['lines']:\n",
    "                for token in line['tokens']:\n",
    "                    if 'position' not in token or token['position'] == 'B' or token['position'] == 'U':\n",
    "                        if 'type' in token:\n",
    "                            result += token['type'] + ' '\n",
    "                        elif 'original' in token:\n",
    "                            result += token['original'] + ' '\n",
    "                        elif 'text' in token:\n",
    "                            result += token['text'] + ' '\n",
    "                result += '\\n'\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Number of words: 15671\nNumber of image-stuff: 50\nAverage number of words per image-stuff: 313.42\nNumber of samples / Number of words per sample: 0.15953034267117605\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "IMAGE_STUFF_DIR = 'image-stuff/'\n",
    "# IN_FILE = IMAGE_STUFF_DIR + '004028867_00135.json'\n",
    "image_stuff_file_list = [f for f in listdir(IMAGE_STUFF_DIR) if isfile(join(IMAGE_STUFF_DIR, f))]\n",
    "\n",
    "number_of_words = 0\n",
    "entity_texts = []\n",
    "for file in image_stuff_file_list:\n",
    "    with open(IMAGE_STUFF_DIR + file) as image_stuff:\n",
    "        image_stuff_json = json.load(image_stuff)\n",
    "    regions = image_stuff_json['regions']\n",
    "    entity_text = get_entity_text(regions)\n",
    "    entity_texts.append(entity_text)\n",
    "    # print(entity_text)\n",
    "    word_list = entity_text.split()\n",
    "    number_of_words += len(word_list)\n",
    "\n",
    "print('Number of words: ' + str(number_of_words))\n",
    "print('Number of image-stuff: ' + str(len(entity_texts)))\n",
    "print('Average number of words per image-stuff: ' + str(number_of_words / len(entity_texts)))\n",
    "print('Number of samples / Number of words per sample: ' + str(50 / 313.42))\n",
    "\n",
    "# I would need 500,000 samples to make it over 1500 and follow the other flows.\n",
    "# According to google, since (Number of samples / Number of words per sample) < 1500\n",
    "# Tokenize the text as n-grams and use a\n",
    "# simple multi-layer perceptron (MLP) model to classify them (left branch in the\n",
    "# flowchart below):\n",
    "#   a. Split the samples into word n-grams; convert the n-grams into vectors.\n",
    "#   b. Score the importance of the vectors and then select the top 20K using the scores.\n",
    "#   c. Build an MLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "En DATE en COREF_LOCATION \ny ORGANIZATION_RELIGIOUS COREF el TITLE PERSON OCCUPATION encargado \ny de dicha . \nEVENT_VITAL solemnemente y puse los Santos . óleos a PERSON \n\nPERSON de AGE de EVENT_VITAL FAMILY_MEMBER de \n↔ \nPERSON y de PERSON fue COREF NONFAMILY \nPERSON EVENT_VITAL con PERSON de \n⌨ \ndicha : COREF advertí COREF obligación y parentesco espiritual \ny lo firmé \nPERSON \nEn DATE \n\nEn esta ORGANIZATION_RELIGIOUS COREF el TITLE PERSON \nOCCUPATION encargado de dicha EVENT_VITAL solemnemente \n⌨ \ny puse los Santos óleos a PERSON de AGE de EVENT_VITAL \nFAMILY_MEMBER de PERSON y de PERSON de \n⌨ \nLOCALE fue COREF NONFAMILY PERSON EVENT_VITAL \ncon PERSON de LOCALE LOCALE \nle advertí COREF obligación y parentesco espiritual y lo firmé \nPERSON \n⌨ \n⌨ ⌨ ⌨ \n✓ \nPERSON DATE \nel \nlos entre \n⌨ \nPueblo \n⌨ \ncomo OCCUPATION propio la \n⌨ \nDoctora \n, nombrado según la ley \nPor el PERSON de este ario - \nLOCALE ; \n✍ \nfirmé \nPERSON \n\n\n\n\n\nEn DATE en \n⌨ \nde esta ORGANIZATION_RELIGIOUS COREF el TITLE PERSON ( V. ₱ ) \nEVENT_VITAL solemnemente y puse los Santos Óleos y PERSON \nde AGE de EVENT_VITAL FAMILY_MEMBER de PERSON y de \n✍ \nPERSON de COREF_LOCATION fueron COREF FAMILY_MEMBER PERSON \ny COREF FAMILY_MEMBER PERSON de dicho les adver ⌨ \nCOREF obligación y parentesco espiritual y lo firmé \n⌨ \nPERSON \nCOREF_GENDER . PERSON \nEn DATE en esta ORGANIZATION_RELIGIOUS \n\nCOREF el TITLE PERSON ( V. P. ) EVENT_VITAL \n⌨ \nsolemnemente y puse los Santos . óleos a PERSON de un \n✓ \ndías de EVENT_VITAL FAMILY_MEMBER de PERSON y de PERSON \nde COREF_LOCATION fue COREF NONFAMILY PERSON \nde dicho . COREF advertí COREF obligación y parentesco espiritual \n✍ \nPERSON ✍ \ny lo firmé PERSON Medalla ⌨ ⌨ \nEn DATE en COREF_LOCATION \n⌨ \n3 \nticia ORGANIZATION_RELIGIOUS COREF el TITLE PERSON ( V. ₱ ) bau = \n⌨ \ntice solemnemente y puse los Santos óleos a PERSON \n⌨ \nde AGE de EVENT_VITAL FAMILY_MEMBER de PERSON y de \nPERSON fueron los pad \nPERSON y PERSON de dicho \nCOREF obligación y espiritual parentesco y lo firmé . \nPERSON \nPERSON \n✍ \n⌨ \n⌨ \nEn DATE en cua \nORGANIZATION_RELIGIOUS COREF el TITLE PERSON \ny propio de dicho . EVENT_VITAL solemnemente y puse los Santos Óleos \na PERSON de un día de EVENT_VITAL FAMILY_MEMBER de \nPERSON , y de PERSON de COREF_LOCATION fueron \n COREF NONFAMILY PERSON de dicho . COREF advertí COREF \nobligación y espiritual parentesco y lo firmé \nPERSON ✍ \n⌨ \n⌨ \n\n"
     ]
    }
   ],
   "source": [
    "print(entity_texts[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1. Make N-grams\n",
    "#2. Vectorize the N-grams"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python392jvsc74a57bd0de79b884656db7339e64ed32cd53ff90c4de07c16a2078664001bdbe1b488e3d",
   "display_name": "Python 3.9.2 64-bit ('ace': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "metadata": {
   "interpreter": {
    "hash": "269041e09b63f27e59ba2c99f39562e609f4d8fccf381fbc082437ecbed0d721"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}